import sys, os
import numpy as np
import argparse
from termcolor import cprint
from pylearn2.datasets.mnist import MNIST
from pylearn2.datasets.cifar10 import CIFAR10
from pylearn2.datasets.svhn import SVHN

# Currently available datasets
dataset_factory = {'name' : ('mnist', 'cifar10', 'svhn'),
    'size' : [(1, 28, 28), (3, 32, 32), (3, 28, 28)]}

data_linker_attr = ('#pragma DATA_ALIGN ({var_name}, 64)', '#pragma DATA_SECTION({var_name}, ".sharedram")')
label_linker_attr = ('#pragma DATA_SECTION({var_name}, ".sharedram")',)

c_header = ('/*This file is automatically generated. Do not modify.\n'
    'This file contains images from below test dataset.\n'
    '*/\n')
h_header = ('/*This file is automatically generated. Do not modify.\n'
    'This file contains images from below test dataset.\n'
    '*/\n')

def parse_args():
    """
    """
    parser = argparse.ArgumentParser(description='Dataset dumper')
    parser.add_argument('--dset', dest='dataset', help='Dataset to be dumped. Available datasets are : {:s}'.format(dataset_factory['name']))
    parser.add_argument('--nimg', dest='no_imgs', help='Number of images to dump into C file')

    if(len(sys.argv) < 3):
        parser.print_help()
        sys.exit()
    args = parser.parse_args()

    return args

def _get_dataset(dataset, no_imgs):
    """ Dump machine learning dataset into C source file and create a header file with
    array declaration and few macro definition
    """
    dataset = dataset.lower()
    if(dataset not in dataset_factory['name']):
        print('Dataset is not in the factory')
        sys.exit()

    if(dataset == 'mnist'):
        print('Reading MNIST dataset from pylearn2 database')
        data = MNIST(which_set='test')
        if(no_imgs > data.X.shape[0]):
            cprint('Only {:d} images are available in this dataset. Dumping only those many'.format(data.X.shape[0]), 'red')
        data_x = data.X[0:min(no_imgs, data.X.shape[0])]
        data_y = data.y[0:min(no_imgs, data.y.shape[0])]
        data_x = np.uint8(data_x * 255) # conversion from 0 -> 0.99 to 0->255

    elif(dataset == 'cifar10'):
        print('Reading CIFAR-10 dataset from pylearn2 database')
        data = CIFAR10(which_set='test')

        if(no_imgs > data.X.shape[0]):
            cprint('Only {:d} images are available in this dataset. Dumping only those many'.format(data.X.shape[0]), 'red')
        data_x = data.X[0:min(no_imgs, data.X.shape[0])]
        data_y = data.y[0:min(no_imgs, data.y.shape[0])]
        data_x = np.uint8(data_x)  # already in the range 0 -> 255

    elif(dataset == 'svhn'):
        cprint('Not supported', 'red')
        return
    
    return data_x, data_y

def dump_dataset(dataset, no_imgs):
    """
    """
    data, labels = _get_dataset(dataset, no_imgs)

    image_cfile_name = dataset + '_test_images.c'
    image_hfile_name = dataset + '_test_images.h'
    image_array_name = dataset + '_image_data'
    label_array_name = dataset + '_image_labels'
    def_no_images = 'NO_TEST_IMAGES'
    def_image_height = 'TEST_IMAME_HEIGHT' 
    def_image_width = 'TEST_IMAGE_WIDTH'
    def_no_channels = 'TEST_IMAGE_CHANELS'

    image_dim = dataset_factory['size'][dataset_factory['name'].index(dataset)]
    header_protect = '_' + dataset.upper() + '_TEST_IMAGES_H_'

    h_cfile = open(image_cfile_name, 'w')
    h_hfile = open(image_hfile_name, 'w')

    # dump header documentation
    h_cfile.write(c_header)
    h_hfile.write(h_header)
    h_hfile.write('#ifndef ' + header_protect + '\n' + '#define ' + header_protect + '\n'
        '#include "stdint.h"\n\n')

    h_hfile.write('#define {:s}\t({:d})\n\n'.format(def_no_images, no_imgs))
    h_hfile.write('#define {:s}\t({:d})\n\n'.format(def_no_channels, image_dim[0]))
    h_hfile.write('#define {:s}\t({:d})\n\n'.format(def_image_height, image_dim[1]))
    h_hfile.write('#define {:s}\t({:d})\n\n'.format(def_image_width, image_dim[2]))

    h_hfile.write('extern const uint8_t {:s}[{:s}][{:s} * {:s} * {:s}];\n\n'.format(image_array_name,
        def_no_images, def_no_channels, def_image_height, def_image_width))
    h_hfile.write('extern const uint32_t {:s}[{:s}];\n\n'.format(label_array_name, def_no_images))

    h_cfile.write('#include "{:s}"\n\n'.format(image_hfile_name))

    # include linker attributes for this array if any
    for attr in data_linker_attr:
        h_cfile.write(attr.format(var_name=image_array_name) + '\n')

    h_cfile.write('const uint8_t {:s}[{:s}][{:s} * {:s} * {:s}] = '.format(image_array_name,
        def_no_images, def_no_channels, def_image_height, def_image_width) + '{\n')

    # dump image data
    cnt = 0
    for img in data:
        h_cfile.write('{')
        for i, p in enumerate(img.tolist()):
            if(i < len(img) - 1):
                h_cfile.write('{:d},'.format(p))
            else:
                h_cfile.write('{:d}'.format(p))
        if(cnt < data.shape[0] - 1):
            h_cfile.write('},\n')
        else:
            h_cfile.write('}\n')
        cnt += 1
    h_cfile.write('};\n\n')
                
    # dump label data
    for attr in label_linker_attr:
        h_cfile.write(attr.format(var_name=label_array_name) + '\n')

    h_cfile.write('const uint32_t {:s}[{:s}] = '.format(label_array_name, def_no_images) + '{\n')
    for i, l in enumerate(labels.reshape(-1).tolist()):
        if(i < len(labels) - 1):
            h_cfile.write('{:d}, '.format(l))
        else:
            h_cfile.write('{:d}'.format(l) + '};')
        
    h_hfile.write('#endif //' + header_protect + '\n')
    h_cfile.close()
    h_hfile.close()
    cprint('Created {:s} and dumped images in 2D array with each row containing 1 unrolled image and labels'.format(image_cfile_name,), 'green')
    cprint('Created {:s} containing the array declaration and constant macro definition'.format(image_hfile_name,), 'green')

if __name__=='__main__':
    args = parse_args()

    dump_dataset(args.dataset, int(args.no_imgs))
